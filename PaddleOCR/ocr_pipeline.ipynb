{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/tungnt/.conda/envs/paddleocr/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "__dir__ = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "sys.path.append(__dir__)\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(__dir__, \"../..\")))\n",
    "\n",
    "os.environ[\"FLAGS_allocator_strategy\"] = \"auto_growth\"\n",
    "\n",
    "import cv2\n",
    "import copy\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from PIL import Image\n",
    "import tools.infer.utility as utility\n",
    "import tools.infer.predict_rec as predict_rec\n",
    "import tools.infer.predict_det as predict_det\n",
    "import tools.infer.predict_cls as predict_cls\n",
    "from ppocr.utils.utility import get_image_file_list, check_and_read\n",
    "from ppocr.utils.logging import get_logger\n",
    "from tools.infer.utility import (\n",
    "    draw_ocr_box_txt,\n",
    "    get_rotate_crop_image,\n",
    "    get_minarea_rect_crop,\n",
    "    slice_generator,\n",
    "    merge_fragmented,\n",
    ")\n",
    "\n",
    "logger = get_logger()\n",
    "\n",
    "\n",
    "class TextSystem(object):\n",
    "    def __init__(self, args):\n",
    "        if not args.show_log:\n",
    "            logger.setLevel(logging.INFO)\n",
    "\n",
    "        self.text_detector = predict_det.TextDetector(args)\n",
    "        self.text_recognizer = predict_rec.TextRecognizer(args)\n",
    "        self.use_angle_cls = args.use_angle_cls\n",
    "        self.drop_score = args.drop_score\n",
    "        if self.use_angle_cls:\n",
    "            self.text_classifier = predict_cls.TextClassifier(args)\n",
    "\n",
    "        self.args = args\n",
    "        self.crop_image_res_index = 0\n",
    "\n",
    "    def draw_crop_rec_res(self, output_dir, img_crop_list, rec_res):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        bbox_num = len(img_crop_list)\n",
    "        for bno in range(bbox_num):\n",
    "            cv2.imwrite(\n",
    "                os.path.join(\n",
    "                    output_dir, f\"mg_crop_{bno+self.crop_image_res_index}.jpg\"\n",
    "                ),\n",
    "                img_crop_list[bno],\n",
    "            )\n",
    "            logger.debug(f\"{bno}, {rec_res[bno]}\")\n",
    "        self.crop_image_res_index += bbox_num\n",
    "\n",
    "    def __call__(self, img, cls=True, slice={}):\n",
    "        time_dict = {\"det\": 0, \"rec\": 0, \"cls\": 0, \"all\": 0}\n",
    "\n",
    "        if img is None:\n",
    "            logger.debug(\"no valid image provided\")\n",
    "            return None, None, time_dict\n",
    "\n",
    "        start = time.time()\n",
    "        ori_im = img.copy()\n",
    "        if slice:\n",
    "            slice_gen = slice_generator(\n",
    "                img,\n",
    "                horizontal_stride=slice[\"horizontal_stride\"],\n",
    "                vertical_stride=slice[\"vertical_stride\"],\n",
    "            )\n",
    "            elapsed = []\n",
    "            dt_slice_boxes = []\n",
    "            for slice_crop, v_start, h_start in slice_gen:\n",
    "                dt_boxes, elapse = self.text_detector(slice_crop, use_slice=True)\n",
    "                if dt_boxes.size:\n",
    "                    dt_boxes[:, :, 0] += h_start\n",
    "                    dt_boxes[:, :, 1] += v_start\n",
    "                    dt_slice_boxes.append(dt_boxes)\n",
    "                    elapsed.append(elapse)\n",
    "            dt_boxes = np.concatenate(dt_slice_boxes)\n",
    "\n",
    "            dt_boxes = merge_fragmented(\n",
    "                boxes=dt_boxes,\n",
    "                x_threshold=slice[\"merge_x_thres\"],\n",
    "                y_threshold=slice[\"merge_y_thres\"],\n",
    "            )\n",
    "            elapse = sum(elapsed)\n",
    "        else:\n",
    "            dt_boxes, elapse = self.text_detector(img)\n",
    "\n",
    "        time_dict[\"det\"] = elapse\n",
    "\n",
    "        if dt_boxes is None:\n",
    "            logger.debug(\"no dt_boxes found, elapsed : {}\".format(elapse))\n",
    "            end = time.time()\n",
    "            time_dict[\"all\"] = end - start\n",
    "            return None, None, time_dict\n",
    "        else:\n",
    "            logger.debug(\n",
    "                \"dt_boxes num : {}, elapsed : {}\".format(len(dt_boxes), elapse)\n",
    "            )\n",
    "        img_crop_list = []\n",
    "\n",
    "        dt_boxes = sorted_boxes(dt_boxes)\n",
    "        height, width = ori_im.shape[:2]\n",
    "        padding = 10\n",
    "        for bno in range(len(dt_boxes)):\n",
    "            tmp_box = copy.deepcopy(dt_boxes[bno])\n",
    "            a, b, c, d = tmp_box\n",
    "            a[0] = max(0, a[0] - padding)\n",
    "            a[1] = max(0, a[1] - padding)\n",
    "\n",
    "            b[0] = min(width, b[0] + padding)\n",
    "            b[1] = max(0, b[1] - padding)\n",
    "\n",
    "            c[0] = min(width, b[0] + padding)\n",
    "            c[1] = min(height, c[1] + padding)\n",
    "\n",
    "            d[0] = max(0, d[0] - padding)\n",
    "            c[1] = min(height, d[1] + padding)\n",
    "\n",
    "            tmp_box = np.array([a, b, c, d])\n",
    "            \n",
    "            if self.args.det_box_type == \"quad\":\n",
    "                img_crop = get_rotate_crop_image(ori_im, tmp_box)\n",
    "            else:\n",
    "                img_crop = get_minarea_rect_crop(ori_im, tmp_box)\n",
    "            img_crop_list.append(img_crop)\n",
    "        if self.use_angle_cls and cls:\n",
    "            img_crop_list, angle_list, elapse = self.text_classifier(img_crop_list)\n",
    "            time_dict[\"cls\"] = elapse\n",
    "            logger.debug(\n",
    "                \"cls num  : {}, elapsed : {}\".format(len(img_crop_list), elapse)\n",
    "            )\n",
    "        if len(img_crop_list) > 1000:\n",
    "            logger.debug(\n",
    "                f\"rec crops num: {len(img_crop_list)}, time and memory cost may be large.\"\n",
    "            )\n",
    "        \n",
    "        rec_res, elapse = self.text_recognizer(img_crop_list)\n",
    "        time_dict[\"rec\"] = elapse\n",
    "        logger.debug(\"rec_res num  : {}, elapsed : {}\".format(len(rec_res), elapse))\n",
    "        if self.args.save_crop_res:\n",
    "            self.draw_crop_rec_res(self.args.crop_res_save_dir, img_crop_list, rec_res)\n",
    "        filter_boxes, filter_rec_res = [], []\n",
    "        for box, rec_result in zip(dt_boxes, rec_res):\n",
    "            text, score = rec_result[0], rec_result[1]\n",
    "            if score >= self.drop_score:\n",
    "                filter_boxes.append(box)\n",
    "                filter_rec_res.append(rec_result)\n",
    "        end = time.time()\n",
    "        time_dict[\"all\"] = end - start\n",
    "        return filter_boxes, filter_rec_res, time_dict\n",
    "\n",
    "\n",
    "def sorted_boxes(dt_boxes):\n",
    "    \"\"\"\n",
    "    Sort text boxes in order from top to bottom, left to right\n",
    "    args:\n",
    "        dt_boxes(array):detected text boxes with shape [4, 2]\n",
    "    return:\n",
    "        sorted boxes(array) with shape [4, 2]\n",
    "    \"\"\"\n",
    "    num_boxes = dt_boxes.shape[0]\n",
    "    sorted_boxes = sorted(dt_boxes, key=lambda x: (x[0][1], x[0][0]))\n",
    "    _boxes = list(sorted_boxes)\n",
    "\n",
    "    for i in range(num_boxes - 1):\n",
    "        for j in range(i, -1, -1):\n",
    "            if abs(_boxes[j + 1][0][1] - _boxes[j][0][1]) < 10 and (\n",
    "                _boxes[j + 1][0][0] < _boxes[j][0][0]\n",
    "            ):\n",
    "                tmp = _boxes[j]\n",
    "                _boxes[j] = _boxes[j + 1]\n",
    "                _boxes[j + 1] = tmp\n",
    "            else:\n",
    "                break\n",
    "    return _boxes\n",
    "\n",
    "\n",
    "# def main(args):\n",
    "#     image_file_list = get_image_file_list(args.image_dir)\n",
    "#     image_file_list = image_file_list[args.process_id :: args.total_process_num]\n",
    "#     text_sys = TextSystem(args)\n",
    "#     is_visualize = True\n",
    "#     font_path = args.vis_font_path\n",
    "#     drop_score = args.drop_score\n",
    "#     draw_img_save_dir = args.draw_img_save_dir\n",
    "#     os.makedirs(draw_img_save_dir, exist_ok=True)\n",
    "#     save_results = []\n",
    "\n",
    "#     logger.info(\n",
    "#         \"In PP-OCRv3, rec_image_shape parameter defaults to '3, 48, 320', \"\n",
    "#         \"if you are using recognition model with PP-OCRv2 or an older version, please set --rec_image_shape='3,32,320\"\n",
    "#     )\n",
    "\n",
    "#     total_time = 0\n",
    "#     cpu_mem, gpu_mem, gpu_util = 0, 0, 0\n",
    "#     _st = time.time()\n",
    "#     count = 0\n",
    "#     for idx, image_file in enumerate(image_file_list):\n",
    "#         img, flag_gif, flag_pdf = check_and_read(image_file)\n",
    "#         if not flag_gif and not flag_pdf:\n",
    "#             img = cv2.imread(image_file)\n",
    "#         if not flag_pdf:\n",
    "#             if img is None:\n",
    "#                 logger.debug(\"error in loading image:{}\".format(image_file))\n",
    "#                 continue\n",
    "#             imgs = [img]\n",
    "#         else:\n",
    "#             page_num = args.page_num\n",
    "#             if page_num > len(img) or page_num == 0:\n",
    "#                 page_num = len(img)\n",
    "#             imgs = img[:page_num]\n",
    "#         for index, img in enumerate(imgs):\n",
    "#             starttime = time.time()\n",
    "#             dt_boxes, rec_res, time_dict = text_sys(img)\n",
    "#             elapse = time.time() - starttime\n",
    "#             total_time += elapse\n",
    "#             if len(imgs) > 1:\n",
    "#                 logger.debug(\n",
    "#                     str(idx)\n",
    "#                     + \"_\"\n",
    "#                     + str(index)\n",
    "#                     + \"  Predict time of %s: %.3fs\" % (image_file, elapse)\n",
    "#                 )\n",
    "#             else:\n",
    "#                 logger.debug(\n",
    "#                     str(idx) + \"  Predict time of %s: %.3fs\" % (image_file, elapse)\n",
    "#                 )\n",
    "#             for text, score in rec_res:\n",
    "#                 logger.debug(\"{}, {:.3f}\".format(text, score))\n",
    "\n",
    "#             res = [\n",
    "#                 {\n",
    "#                     \"transcription\": rec_res[i][0],\n",
    "#                     \"points\": np.array(dt_boxes[i]).astype(np.int32).tolist(),\n",
    "#                 }\n",
    "#                 for i in range(len(dt_boxes))\n",
    "#             ]\n",
    "#             if len(imgs) > 1:\n",
    "#                 save_pred = (\n",
    "#                     os.path.basename(image_file)\n",
    "#                     + \"_\"\n",
    "#                     + str(index)\n",
    "#                     + \"\\t\"\n",
    "#                     + json.dumps(res, ensure_ascii=False)\n",
    "#                     + \"\\n\"\n",
    "#                 )\n",
    "#             else:\n",
    "#                 save_pred = (\n",
    "#                     os.path.basename(image_file)\n",
    "#                     + \"\\t\"\n",
    "#                     + json.dumps(res, ensure_ascii=False)\n",
    "#                     + \"\\n\"\n",
    "#                 )\n",
    "#             save_results.append(save_pred)\n",
    "\n",
    "#             if is_visualize:\n",
    "#                 image = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "#                 boxes = dt_boxes\n",
    "#                 txts = [rec_res[i][0] for i in range(len(rec_res))]\n",
    "#                 scores = [rec_res[i][1] for i in range(len(rec_res))]\n",
    "\n",
    "#                 draw_img = draw_ocr_box_txt(\n",
    "#                     image,\n",
    "#                     boxes,\n",
    "#                     txts,\n",
    "#                     scores,\n",
    "#                     drop_score=drop_score,\n",
    "#                     font_path=font_path,\n",
    "#                 )\n",
    "#                 if flag_gif:\n",
    "#                     save_file = image_file[:-3] + \"png\"\n",
    "#                 elif flag_pdf:\n",
    "#                     save_file = image_file.replace(\".pdf\", \"_\" + str(index) + \".png\")\n",
    "#                 else:\n",
    "#                     save_file = image_file\n",
    "#                 cv2.imwrite(\n",
    "#                     os.path.join(draw_img_save_dir, os.path.basename(save_file)),\n",
    "#                     draw_img[:, :, ::-1],\n",
    "#                 )\n",
    "#                 logger.debug(\n",
    "#                     \"The visualized image saved in {}\".format(\n",
    "#                         os.path.join(draw_img_save_dir, os.path.basename(save_file))\n",
    "#                     )\n",
    "#                 )\n",
    "\n",
    "#     logger.info(\"The predict total time is {}\".format(time.time() - _st))\n",
    "#     if args.benchmark:\n",
    "#         text_sys.text_detector.autolog.report()\n",
    "#         text_sys.text_recognizer.autolog.report()\n",
    "\n",
    "#     with open(\n",
    "#         os.path.join(draw_img_save_dir, \"system_results.txt\"), \"w\", encoding=\"utf-8\"\n",
    "#     ) as f:\n",
    "#         f.writelines(save_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_args = utility.init_args().parse_args(args=[])\n",
    "# predict_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_args.warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_args.add_argument(\"--image_dir\"=\"./test_images/part.png\")\n",
    "# predict_args.image_dir = \"./test_images\"\n",
    "# predict_args = utility.init_args().parse_args(args=[])\n",
    "# predict_args.det_model_dir =\"./trained_models/Multilingual_PP-OCRv3_det_infer/\"\n",
    "# predict_args.rec_model_dir=\"./inference/vi_ver_without_number/\"\n",
    "# predict_args.use_angle_cls=False\n",
    "# predict_args.rec_char_dict_path=\"ppocr/utils/dict/vi_dict.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True:\n",
    "#     if predict_args.use_mp:\n",
    "#         p_list = []\n",
    "#         total_process_num = predict_args.total_process_num\n",
    "#         for process_id in range(total_process_num):\n",
    "#             cmd = (\n",
    "#                 [sys.executable, \"-u\"]\n",
    "#                 + sys.argv\n",
    "#                 + [\"--process_id={}\".format(process_id), \"--use_mp={}\".format(False)]\n",
    "#             )\n",
    "#             p = subprocess.Popen(cmd, stdout=sys.stdout, stderr=sys.stdout)\n",
    "#             p_list.append(p)\n",
    "#         for p in p_list:\n",
    "#             p.wait()\n",
    "#     else:\n",
    "#         main(predict_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def find_horizontal_lines(boxes, tolerance_y=0.005):\n",
    "    # Helper function to check if two boxes are horizontally aligned\n",
    "    def is_horizontally_aligned(boxA, boxB):\n",
    "        x0_A, y0_A, x1_A, y1_A, tA = boxA\n",
    "        x0_B, y0_B, x1_B, y1_B, tB = boxB\n",
    "        if y1_B > y1_A:\n",
    "            v1 = abs(y1_B - y1_A) / (y1_B - y0_B)\n",
    "            v2 = abs(y0_B - y0_A) / (y1_A - y0_A)\n",
    "        else:\n",
    "            v1 = abs(y1_A - y1_B) / (y1_A - y0_A)\n",
    "            v2 = abs(y0_A - y0_B) / (y1_B - y0_B)\n",
    "        # print(\"{0}||{1}: {2:.4f} or {3:.4f}\".format(tA, tB, v1, v2))\n",
    "        return v1 <= tolerance_y or v2 <= tolerance_y\n",
    "\n",
    "    # Group boxes into horizontal lines\n",
    "    adjacency_list = defaultdict(list)\n",
    "    n = len(boxes)\n",
    "\n",
    "    # Build graph: connect boxes that are horizontally aligned\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if is_horizontally_aligned(boxes[i], boxes[j]):\n",
    "                adjacency_list[i].append(j)\n",
    "                adjacency_list[j].append(i)\n",
    "\n",
    "    # Use BFS/DFS to find connected components (horizontal lines)\n",
    "    visited = [False] * n\n",
    "    horizontal_lines = []\n",
    "\n",
    "    def dfs(node, group):\n",
    "        visited[node] = True\n",
    "        group.append(boxes[node])\n",
    "        for neighbor in adjacency_list[node]:\n",
    "            if not visited[neighbor]:\n",
    "                dfs(neighbor, group)\n",
    "\n",
    "    for i in range(n):\n",
    "        if not visited[i]:\n",
    "            group = []\n",
    "            dfs(i, group)\n",
    "            horizontal_lines.append(group)\n",
    "\n",
    "    return horizontal_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_main(img):\n",
    "\n",
    "\n",
    "    args = utility.init_args().parse_args(args=[])\n",
    "    args.det_model_dir =\"./inference/vi_det_db_inference_best_accuracy_with_augmentation\"\n",
    "    args.rec_model_dir=\"./inference/vi_ver_with_number\"\n",
    "    args.use_angle_cls=False\n",
    "    args.save_crop_res=True\n",
    "    args.rec_char_dict_path=\"ppocr/utils/dict/my_vi_dict.txt\"\n",
    "    print(args.draw_img_save_dir)\n",
    "    text_sys = TextSystem(args)\n",
    "    is_visualize = True\n",
    "    font_path = args.vis_font_path\n",
    "    drop_score = args.drop_score\n",
    "    draw_img_save_dir = args.draw_img_save_dir\n",
    "    os.makedirs(draw_img_save_dir, exist_ok=True)\n",
    "    save_results = []\n",
    "\n",
    "    logger.info(\n",
    "        \"In PP-OCRv3, rec_image_shape parameter defaults to '3, 48, 320', \"\n",
    "        \"if you are using recognition model with PP-OCRv2 or an older version, please set --rec_image_shape='3,32,320'\"\n",
    "    )\n",
    "\n",
    "    total_time = 0\n",
    "    cpu_mem, gpu_mem, gpu_util = 0, 0, 0\n",
    "    _st = time.time()\n",
    "    count = 0\n",
    "\n",
    "    starttime = time.time()\n",
    "    dt_boxes, rec_res, time_dict = text_sys(img)\n",
    "    elapse = time.time() - starttime\n",
    "    total_time += elapse\n",
    "    logger.debug(f\"Predict time: {elapse:.3f}s\")\n",
    "    # Merge results\n",
    "    boxes = []\n",
    "    H, W = img.shape[0], img.shape[1]\n",
    "    for bbox, rec_text in zip(dt_boxes, rec_res):\n",
    "        x0 = int(bbox[0][0]) / W\n",
    "        y0 = int(bbox[0][1]) / H\n",
    "        x1 = int(bbox[2][0]) / W\n",
    "        y1 = int(bbox[2][1]) / H\n",
    "        content = rec_text[0]\n",
    "        boxes.append([x0, y0, x1, y1, content])\n",
    "    horizontal_lines = find_horizontal_lines(boxes, tolerance_y=0.5)\n",
    "    all_text = \"\"\n",
    "    for i, line in enumerate(horizontal_lines):\n",
    "        sorted_line = sorted(line, key=lambda x: x[0])\n",
    "        text = \"\"\n",
    "        for box in sorted_line:\n",
    "            text += box[-1] + \" \"\n",
    "        all_text += text + \"\\n\"\n",
    "    if is_visualize:\n",
    "        image = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        boxes = dt_boxes\n",
    "        txts = [rec_res[i][0] for i in range(len(rec_res))]\n",
    "        scores = [rec_res[i][1] for i in range(len(rec_res))]\n",
    "\n",
    "        draw_img = draw_ocr_box_txt(\n",
    "            image,\n",
    "            boxes,\n",
    "            txts,\n",
    "            scores,\n",
    "            drop_score=drop_score,\n",
    "            font_path=font_path,\n",
    "        )\n",
    "        save_file = \"newest_result.png\"\n",
    "        \n",
    "        cv2.imwrite(\n",
    "            os.path.join(draw_img_save_dir, os.path.basename(save_file)),\n",
    "            draw_img[:, :, ::-1],\n",
    "        )\n",
    "        print(f\"The visualized image saved in {os.path.join(draw_img_save_dir, os.path.basename(save_file))}\")\n",
    "\n",
    "        \n",
    "\n",
    "    return all_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image_path = \"/raid/kientdt/shared_drive_cv/ocr/tungnt/document_extraction/data/test/Test1.png\"\n",
    "# Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./inference_results\n",
      "[2025/01/02 01:16:59] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n",
      "[2025/01/02 01:17:00] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n",
      "[2025/01/02 01:17:00] ppocr INFO: In PP-OCRv3, rec_image_shape parameter defaults to '3, 48, 320', if you are using recognition model with PP-OCRv2 or an older version, please set --rec_image_shape='3,32,320'\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: dt_boxes num : 150, elapsed : 0.715064525604248\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: rec_res num  : 150, elapsed : 0.17964673042297363\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 0, ('1.', 0.9997233152389526)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 1, ('Lý', 0.9993984699249268)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 2, ('do', 0.998295783996582)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 3, ('trình', 0.9658452272415161)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 4, ('Ngay', 0.8951688408851624)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 5, ('từ', 0.9990770220756531)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 6, ('khi', 0.8721742630004883)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 7, ('bắt', 0.9402448534965515)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 8, ('t đầu', 0.9563633799552917)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 9, ('giai', 0.9651504755020142)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 10, ('đoạn', 0.9006086587905884)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 11, ('1', 0.9425575733184814)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 12, ('của', 0.998420774936676)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 13, ('dự', 0.9918807744979858)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 14, (' án', 0.8610214591026306)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 15, ('xây', 0.7467853426933289)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 16, ('dựng', 0.9670155048370361)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 17, ('hệ', 0.9724668264389038)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 18, ('thống', 0.8203600645065308)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 19, ('cơ', 0.99554842710495)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 20, ('sở', 0.977730929851532)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 21, ('dữ', 0.9951634407043457)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 22, ('liệu', 0.979775071144104)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 23, ('tìm', 0.9991710782051086)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 24, ('kiếm', 0.9508332014083862)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 25, ('thăm', 0.9825052618980408)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 26, ('dò', 0.9749748706817627)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 27, ('và', 0.9887628555297852)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 28, ('khai', 0.9864486455917358)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 29, ('thác', 0.9337589740753174)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 30, ('dầu', 0.8859615325927734)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 31, ('khí', 0.9046943187713623)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 32, ('í 2', 0.9930869936943054)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 33, ('cho', 0.9824835658073425)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 34, ('PVN,', 0.9924064874649048)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 35, ('Ban', 0.9991922974586487)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 36, ('Tổng', 0.9836792349815369)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 37, ('giám', 0.9666529893875122)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 38, ('đốc', 0.9903789162635803)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 39, ('VTS', 0.9542784690856934)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 40, ('đã', 0.9969421625137329)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 41, ('giao', 0.9999839067459106)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 42, ('nhiệm', 0.9839586019515991)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 43, ('vụ', 0.9895192384719849)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 44, ('cho', 0.8945890069007874)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 45, ('trung', 0.9429787397384644)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 46, ('tâm', 0.9932871460914612)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 47, ('Dịch', 0.993708610534668)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 48, ('vụ', 0.750969648361206)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 49, ('3', 0.8918527364730835)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 50, ('phân', 0.9655961990356445)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 51, ('tích', 0.9836692810058594)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 52, ('dữ', 0.9970732927322388)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 53, ('liệu', 0.970311164855957)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 54, ('nghiên', 0.9723706841468811)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 55, ('cứu', 0.9981597065925598)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 56, ('1 23,', 0.8245226144790649)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 57, (', phát', 0.9330363273620605)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 58, ('ttriển', 0.956101655960083)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 59, ('các', 0.9999533295631409)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 60, ('bài', 0.8529930710792542)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 61, ('toán', 0.9571301937103271)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 62, ('ứng', 0.9568988680839539)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 63, ('dụng', 0.9548100233078003)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 64, ('khoa', 0.9704734086990356)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 65, ('học', 0.9542307257652283)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 66, ('dữ', 0.9983384013175964)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 67, ('liệu', 0.9892269968986511)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 68, ('5', 0.988201916217804)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 69, ('và', 0.9929294586181641)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 70, ('trí', 0.9822907447814941)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 71, (' tuệ', 0.8587861061096191)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 72, ('nhân', 0.993415355682373)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 73, ('12', 0.9902719259262085)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 74, ('tạo', 0.9581784605979919)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 75, ('trong', 0.868719220161438)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 76, ('việc', 0.9903345704078674)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 77, ('nâng', 0.9755984544754028)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 78, ('cao', 0.999928891658783)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 79, ('hiệu', 0.9884055256843567)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 80, ('1quả', 0.962073028087616)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 81, ('4', 0.8714774250984192)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 82, ('các', 0.9773163795471191)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 83, ('hoạt', 0.9718223810195923)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 84, ('tđộng', 0.9883559346199036)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 85, ('tìm', 0.8113384246826172)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 86, ('kiếm', 0.9625949859619141)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 87, ('thăm', 0.9657905697822571)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 88, ('dò', 0.9764883518218994)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 89, ('và', 0.992505669593811)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 90, ('9', 0.9758008718490601)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 91, ('khai', 0.9354928135871887)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 92, ('thác', 0.7760255336761475)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 93, ('dầu', 0.8766151070594788)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 94, ('khí.', 0.9294133186340332)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 95, ('. Trung', 0.9380757212638855)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 96, ('tâm', 0.9934978485107422)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 97, ('Dịch', 0.9998265504837036)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 98, ('vụ', 0.9503412842750549)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 99, ('Phân', 0.9759683012962341)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 100, ('tích', 0.9858842492103577)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 101, ('dữ', 0.9962211847305298)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 102, ('6', 0.9226602911949158)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 103, ('liệu', 0.987947404384613)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 104, ('đã', 0.9973451495170593)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 105, ('chủ', 0.9773750305175781)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 106, ('động', 0.9768263697624207)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 107, ('nghiên', 0.9769272804260254)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 108, ('cứu,', 0.8812272548675537)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 109, ('phát', 0.9872458577156067)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 110, ('triển', 0.8746918439865112)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 111, ('tri', 0.8007517457008362)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 112, ('thức', 0.9037471413612366)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 113, ('chuyên', 0.9806954264640808)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 114, ('ngành', 0.9995924830436707)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 115, ('dầu', 0.9921024441719055)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 116, ('khí,', 0.9986647367477417)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 117, ('kết', 0.9389248490333557)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 118, ('t hợp', 0.9292716979980469)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 119, ('với', 0.9981388449668884)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 120, ('nền', 0.9333982467651367)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 121, ('tảng', 0.7639482021331787)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 122, ('vững', 0.9944303035736084)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 123, ('chắc', 0.9716565608978271)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 124, ('trong', 0.9002993702888489)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 125, ('lĩnh', 0.9990547299385071)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 126, ('vực', 0.9683716893196106)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 127, ('khoa', 0.95036780834198)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 128, ('học', 0.9770302772521973)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 129, ('dữ', 0.9972734451293945)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 130, ('liệu,', 0.9707877039909363)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 131, ('để', 0.9979361891746521)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 132, ('phát', 0.9749292731285095)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 133, ('t triển', 0.9200437664985657)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 134, ('thành', 0.9621559977531433)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 135, ('công', 0.9959508180618286)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 136, ('giải', 0.9766684770584106)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 137, ('pháp', 0.9522473812103271)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 138, ('tối', 0.9924539923667908)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 139, ('i ưu', 0.8988226652145386)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 140, ('1hóa', 0.8629049062728882)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 141, ('quy', 0.9908041954040527)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 142, ('trình', 0.865890622138977)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 143, ('xử', 0.9955019950866699)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 144, ('lý', 0.9886797666549683)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 145, ('và', 0.9940893650054932)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 146, ('minh', 0.96336829662323)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 147, ('giải', 0.942084550857544)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 148, ('i dữ', 0.8860388994216919)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: 149, ('liệu', 0.9580875635147095)\n",
      "[2025/01/02 01:17:01] ppocr DEBUG: Predict time: 0.993s\n",
      "The visualized image saved in ./inference_results/newest_result.png\n"
     ]
    }
   ],
   "source": [
    "image = cv2.cvtColor(cv2.imread(image_path),cv2.COLOR_BGR2RGB)\n",
    "my_text = my_main(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Lý do trình \\nNgay từ khi bắt t đầu giai đoạn 1 của dự  án xây dựng hệ thng cơ sở dữ liệu \\ntìm kiếm thăm dò và khai thác dầu khí í 2 cho PVN, Ban Tổng giám đốc VTS đã \\ngiao nhiệm vụ cho trung tâm Dịch vụ 13 phân tích dữ liệu nghiên cứu 123, , phát ttriển \\ncác ài toán ứng dụng khoa học dữ liệu 5 và trí tuệ nhân 12 tạo trong việc nâng \\ncao hiệu 1quả 4 các hoạt tđộng tìm kiếm thăm dò và 9 khai thác dầu khí. . Trung tâm \\nDịch vụ Phân tích dữ 6 liệu đã chủ động nghiên cứu, phát triển tri thức chuyên \\nngành dầu khí, kết t hợp với nền tảng vững chắc trong lĩnh vực khoa học dữ liệu, \\nđể phát ttriển thành công giải ipháp tối i ưu hóa quy trình xử lý và minh giải i dữ liệu \\n'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"/raid/tungpth/shared_drive_cv/ocr/kientdt/PaddleOCR/ocr_trial\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
