{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "__dir__ = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "sys.path.append(__dir__)\n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(__dir__, \"../..\")))\n",
    "\n",
    "os.environ[\"FLAGS_allocator_strategy\"] = \"auto_growth\"\n",
    "\n",
    "import cv2\n",
    "import copy\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from PIL import Image\n",
    "import tools.infer.utility as utility\n",
    "import tools.infer.predict_rec as predict_rec\n",
    "import tools.infer.predict_det as predict_det\n",
    "import tools.infer.predict_cls as predict_cls\n",
    "from ppocr.utils.utility import get_image_file_list, check_and_read\n",
    "from ppocr.utils.logging import get_logger\n",
    "from tools.infer.utility import (\n",
    "    draw_ocr_box_txt,\n",
    "    get_rotate_crop_image,\n",
    "    get_minarea_rect_crop,\n",
    "    slice_generator,\n",
    "    merge_fragmented,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logger = get_logger()\n",
    "\n",
    "\n",
    "class TextSystem(object):\n",
    "    def __init__(self, args):\n",
    "        if not args.show_log:\n",
    "            logger.setLevel(logging.INFO)\n",
    "\n",
    "        self.text_detector = predict_det.TextDetector(args)\n",
    "        self.text_recognizer = predict_rec.TextRecognizer(args)\n",
    "        self.use_angle_cls = args.use_angle_cls\n",
    "        self.drop_score = args.drop_score\n",
    "        if self.use_angle_cls:\n",
    "            self.text_classifier = predict_cls.TextClassifier(args)\n",
    "\n",
    "        self.args = args\n",
    "        self.crop_image_res_index = 0\n",
    "\n",
    "    def draw_crop_rec_res(self, output_dir, img_crop_list, rec_res):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        bbox_num = len(img_crop_list)\n",
    "        for bno in range(bbox_num):\n",
    "            cv2.imwrite(\n",
    "                os.path.join(\n",
    "                    output_dir, f\"mg_crop_{bno+self.crop_image_res_index}.jpg\"\n",
    "                ),\n",
    "                img_crop_list[bno],\n",
    "            )\n",
    "            logger.debug(f\"{bno}, {rec_res[bno]}\")\n",
    "        self.crop_image_res_index += bbox_num\n",
    "\n",
    "    def __call__(self, img, cls=True, slice={}):\n",
    "        time_dict = {\"det\": 0, \"rec\": 0, \"cls\": 0, \"all\": 0}\n",
    "\n",
    "        if img is None:\n",
    "            logger.debug(\"no valid image provided\")\n",
    "            return None, None, time_dict\n",
    "\n",
    "        start = time.time()\n",
    "        ori_im = img.copy()\n",
    "        if slice:\n",
    "            slice_gen = slice_generator(\n",
    "                img,\n",
    "                horizontal_stride=slice[\"horizontal_stride\"],\n",
    "                vertical_stride=slice[\"vertical_stride\"],\n",
    "            )\n",
    "            elapsed = []\n",
    "            dt_slice_boxes = []\n",
    "            for slice_crop, v_start, h_start in slice_gen:\n",
    "                dt_boxes, elapse = self.text_detector(slice_crop, use_slice=True)\n",
    "                if dt_boxes.size:\n",
    "                    dt_boxes[:, :, 0] += h_start\n",
    "                    dt_boxes[:, :, 1] += v_start\n",
    "                    dt_slice_boxes.append(dt_boxes)\n",
    "                    elapsed.append(elapse)\n",
    "            dt_boxes = np.concatenate(dt_slice_boxes)\n",
    "\n",
    "            dt_boxes = merge_fragmented(\n",
    "                boxes=dt_boxes,\n",
    "                x_threshold=slice[\"merge_x_thres\"],\n",
    "                y_threshold=slice[\"merge_y_thres\"],\n",
    "            )\n",
    "            elapse = sum(elapsed)\n",
    "        else:\n",
    "            dt_boxes, elapse = self.text_detector(img)\n",
    "\n",
    "        time_dict[\"det\"] = elapse\n",
    "\n",
    "        if dt_boxes is None:\n",
    "            logger.debug(\"no dt_boxes found, elapsed : {}\".format(elapse))\n",
    "            end = time.time()\n",
    "            time_dict[\"all\"] = end - start\n",
    "            return None, None, time_dict\n",
    "        else:\n",
    "            logger.debug(\n",
    "                \"dt_boxes num : {}, elapsed : {}\".format(len(dt_boxes), elapse)\n",
    "            )\n",
    "        img_crop_list = []\n",
    "\n",
    "        dt_boxes = sorted_boxes(dt_boxes)\n",
    "\n",
    "        for bno in range(len(dt_boxes)):\n",
    "            tmp_box = copy.deepcopy(dt_boxes[bno])\n",
    "            if self.args.det_box_type == \"quad\":\n",
    "                img_crop = get_rotate_crop_image(ori_im, tmp_box)\n",
    "            else:\n",
    "                img_crop = get_minarea_rect_crop(ori_im, tmp_box)\n",
    "            img_crop_list.append(img_crop)\n",
    "        if self.use_angle_cls and cls:\n",
    "            img_crop_list, angle_list, elapse = self.text_classifier(img_crop_list)\n",
    "            time_dict[\"cls\"] = elapse\n",
    "            logger.debug(\n",
    "                \"cls num  : {}, elapsed : {}\".format(len(img_crop_list), elapse)\n",
    "            )\n",
    "        if len(img_crop_list) > 1000:\n",
    "            logger.debug(\n",
    "                f\"rec crops num: {len(img_crop_list)}, time and memory cost may be large.\"\n",
    "            )\n",
    "\n",
    "        rec_res, elapse = self.text_recognizer(img_crop_list)\n",
    "        time_dict[\"rec\"] = elapse\n",
    "        logger.debug(\"rec_res num  : {}, elapsed : {}\".format(len(rec_res), elapse))\n",
    "        if self.args.save_crop_res:\n",
    "            self.draw_crop_rec_res(self.args.crop_res_save_dir, img_crop_list, rec_res)\n",
    "        filter_boxes, filter_rec_res = [], []\n",
    "        for box, rec_result in zip(dt_boxes, rec_res):\n",
    "            text, score = rec_result[0], rec_result[1]\n",
    "            if score >= self.drop_score:\n",
    "                filter_boxes.append(box)\n",
    "                filter_rec_res.append(rec_result)\n",
    "        end = time.time()\n",
    "        time_dict[\"all\"] = end - start\n",
    "        return filter_boxes, filter_rec_res, time_dict\n",
    "\n",
    "\n",
    "def sorted_boxes(dt_boxes):\n",
    "    \"\"\"\n",
    "    Sort text boxes in order from top to bottom, left to right\n",
    "    args:\n",
    "        dt_boxes(array):detected text boxes with shape [4, 2]\n",
    "    return:\n",
    "        sorted boxes(array) with shape [4, 2]\n",
    "    \"\"\"\n",
    "    num_boxes = dt_boxes.shape[0]\n",
    "    sorted_boxes = sorted(dt_boxes, key=lambda x: (x[0][1], x[0][0]))\n",
    "    _boxes = list(sorted_boxes)\n",
    "\n",
    "    for i in range(num_boxes - 1):\n",
    "        for j in range(i, -1, -1):\n",
    "            if abs(_boxes[j + 1][0][1] - _boxes[j][0][1]) < 10 and (\n",
    "                _boxes[j + 1][0][0] < _boxes[j][0][0]\n",
    "            ):\n",
    "                tmp = _boxes[j]\n",
    "                _boxes[j] = _boxes[j + 1]\n",
    "                _boxes[j + 1] = tmp\n",
    "            else:\n",
    "                break\n",
    "    return _boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(\"./trained_models/Multilingual_PP-OCRv3_det_infer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/raid/project_drive/CV/ocr/kientdt/PaddleOCR/rec_weights.zip'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.make_archive(\"rec_weights\", \"zip\", \"./inference/vi_ver_without_number/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/12/25 02:21:06] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n"
     ]
    }
   ],
   "source": [
    "args = utility.init_args().parse_args(args=[])\n",
    "args.det_model_dir =\"./trained_models/Multilingual_PP-OCRv3_det_infer/\"\n",
    "args.rec_model_dir=\"./inference/vi_ver_without_number/\"\n",
    "args.use_angle_cls=False\n",
    "args.rec_char_dict_path=\"ppocr/utils/dict/vi_dict.txt\"\n",
    "text_sys = TextSystem(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_main(img):\n",
    "\n",
    "\n",
    "    \n",
    "    is_visualize = True\n",
    "    font_path = args.vis_font_path\n",
    "    drop_score = args.drop_score\n",
    "    draw_img_save_dir = args.draw_img_save_dir\n",
    "    os.makedirs(draw_img_save_dir, exist_ok=True)\n",
    "    save_results = []\n",
    "\n",
    "    logger.info(\n",
    "        \"In PP-OCRv3, rec_image_shape parameter defaults to '3, 48, 320', \"\n",
    "        \"if you are using recognition model with PP-OCRv2 or an older version, please set --rec_image_shape='3,32,320'\"\n",
    "    )\n",
    "\n",
    "    total_time = 0\n",
    "    cpu_mem, gpu_mem, gpu_util = 0, 0, 0\n",
    "    _st = time.time()\n",
    "    count = 0\n",
    "\n",
    "    starttime = time.time()\n",
    "    dt_boxes, rec_res, time_dict = text_sys(img)\n",
    "    elapse = time.time() - starttime\n",
    "    total_time += elapse\n",
    "    logger.debug(f\"Predict time: {elapse:.3f}s\")\n",
    "    all_text = \" \".join([line[0] for line in rec_res])\n",
    "    return dt_boxes, rec_res, time_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/12/25 02:16:01] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"./test_images/part.png\")\n",
    "results = my_main(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cứ Thôrg tíên tịch số Căn ttr 1/21[TTTT-BKHCN-BỰ ngày 11/Gt/2G15 của Liến Bộ Khoạ học trà Công nghệ tà Bộ Nội v hướng đẫn thực hiện việc sổ nhiệm và xếp lương theo chức danh nghề nghiệp đổi tới ưiếr crức chuyến ngành khoa học và công nghệ;'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cứ Thông liên tịch số Găn tư TTTIrBKHCNBN ngày i của Liên Bộ Khoa học vả Công nghệ và Bộ Nội vụ hướng dẫn thực hiện việc bổ nhiệm và xếp lương theo chức danh nghề nghiệp đổi với viên clức chuyển ngành khoa học và công nghệ'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
